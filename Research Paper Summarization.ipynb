{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb233ce8-6739-484d-8ab3-f7244a6d408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.25.4-cp39-abi3-win_amd64.whl (16.6 MB)\n",
      "Installing collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.25.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Adeeshunnikrishnan\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d413c1ca-4f6d-4551-bf4a-9a7502eb1598",
   "metadata": {},
   "source": [
    "# Extracting text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f890b0-e6ed-4825-8117-40aa98dfa1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arXiv:2503.09776v1  [cs.NI]  12 Mar 2025\n",
      "A Short Scalability Study on the SeQUeNCe\n",
      "Parallel Quantum Network Simulator\n",
      "Aaron Welch\n",
      "Computational Sciences &\n",
      "Engineering Division\n",
      "Oak Ridge National Laboratory, USA\n",
      "welchda@ornl.gov\n",
      "Mariam Kiran\n",
      "Computational Sciences &\n",
      "Engineering Division\n",
      "Oak Ridge National Laboratory, USA\n",
      "kiranm@ornl.gov\n",
      "Abstract‚ÄîAs quantum networking continues to grow in im-\n",
      "portance, its study is of interest to an ever wider community and\n",
      "at an increasing scale. However, the development of its physical\n",
      "infrastructure remains burdensome, and services providing third-\n",
      "party access are not enough to meet demand. A variety of\n",
      "simulation frameworks provide a method for testing aspects of\n",
      "such systems on commodity hardware, but are predominantly\n",
      "serial and thus unable to scale to larger networks and/or\n",
      "workloads. One effort to address this was focused on parallelising\n",
      "the SeQUeNCe discrete event simulator, though it has yet to be\n",
      "proven to work well across system architectur\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)  # Open PDF file\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + \"\\n\"  # Extract text from each page\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "pdf_text = extract_text_from_pdf(\"quantum.pdf\")\n",
    "print(pdf_text[:1000])  # Print first 1000 characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63977b36-d98f-4c62-ae0c-a98c78002f35",
   "metadata": {},
   "source": [
    "# Removing newlines, extra spaces, citation numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e4a807e-7458-4c0a-b88d-9e266a4828f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arXiv:2503.09776v1 [cs.NI] 12 Mar 2025 A Short Scalability Study on the SeQUeNCe Parallel Quantum Network Simulator Aaron Welch Computational Sciences & Engineering Division Oak Ridge National Laboratory, USA welchda@ornl.gov Mariam Kiran Computational Sciences & Engineering Division Oak Ridge National Laboratory, USA kiranm@ornl.gov Abstract‚ÄîAs quantum networking continues to grow in im- portance, its study is of interest to an ever wider community and at an increasing scale. However, the development of its physical infrastructure remains burdensome, and services providing third- party access are not enough to meet demand. A variety of simulation frameworks provide a method for testing aspects of such systems on commodity hardware, but are predominantly serial and thus unable to scale to larger networks and/or workloads. One effort to address this was focused on parallelising the SeQUeNCe discrete event simulator, though it has yet to be proven to work well across system architectures\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\n+', '\\n', text)  # Remove excessive newlines\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'\\[[0-9]+\\]', '', text)  # Remove citation numbers like [1], [2]\n",
    "    return text.strip()\n",
    "\n",
    "cleaned_text = clean_text(pdf_text)\n",
    "print(cleaned_text[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a55162-b7ad-442e-bbd8-24b3d18b63d3",
   "metadata": {},
   "source": [
    "# Break Long Research Papers into Chunks for Summarization\n",
    "* Most models have a token limit (e.g., BART and T5 can only handle 512 tokens per input).\n",
    "* Long documents need to be split into smaller chunks for effective summarization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b205b-c6bc-4759-b443-a7615e976a91",
   "metadata": {},
   "source": [
    "# üìå 1Ô∏è‚É£ Define Chunk Size (Based on Model Limitations)\n",
    "* BART & T5: Can process 512 tokens (~400 words) at a time.\n",
    "* LongFormer & BigBird: Can process 4,096+ tokens (but are slower).\n",
    "* Best Practice: Split text into chunks of ~400 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea488cd-24f9-4ecd-ba79-ee741fde193c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 10\n",
      "arXiv:2503.09776v1 [cs.NI] 12 Mar 2025 A Short Scalability Study on the SeQUeNCe Parallel Quantum Network Simulator Aaron Welch Computational Sciences & Engineering Division Oak Ridge National Laboratory, USA welchda@ornl.gov Mariam Kiran Computational Sciences & Engineering Division Oak Ridge National Laboratory, USA kiranm@ornl.gov Abstract‚ÄîAs quantum networking continues to grow in im- portance, its study is of interest to an ever wider community and at an increasing scale. However, the development of its physical infrastructure remains burdensome, and services providing third- party access are not enough to meet demand. A variety of simulation frameworks provide a method for testing aspects of such systems on commodity hardware, but are predominantly serial and thus unable to scale to larger networks and/or workloads. One effort to address this was focused on parallelising the SeQUeNCe discrete event simulator, though it has yet to be proven to work well across system architectures or at larger scales. Therein lies the contribution of this work ‚Äî to more deeply examine its scalability using ORNL‚Äôs Frontier. Our results provide new insight into its scalability behaviour, and we examine its strategy and how it may be able to be improved. Index Terms‚Äîquantum networking, discrete event simulation, distributed computing I. INTRODUCTION Quantum networks are argued to be the next generation for communication networks that will deliver entanglement and connect distributed quantum physics devices such as quantum computers, sensors, and detectors ‚Äì. Instead of classical ‚Äúbits‚Äù, qubits are transmitted that encode information using the photon spin representation. Quantum networks are being designed to develop ultra-secure and highly accurate sensor networks for science and commercial applications . There are numerous industry efforts developing new hard- ware, protocols, and tools to enable quantum information exchange , using discrete and continuous variable demon- strations, each bringing their own capabilities , Ô¨Åber-optical transmission or free space point-to-point communication. However, network loss plays a huge role in guaranteeing the validity of the quantum states, with current implementations limited to a 300 km distance . Using quantum repeaters, one can extend these to longer distances such that quantum states can be refreshed or preserved ‚Äì. In order to design more efÔ¨Åcient quantum networks and provide a cheap alternative for testing and analysis, quantum network simulations have been developed to help deÔ¨Åne use cases, and collect data to build reliable devices. However, these have been largely sequential and thus limited to small networks and time scales. SeQUeNCe addresses this limitation\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def split_text_into_chunks(text, max_words=400):\n",
    "    words = text.split()  # Split text into words\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        if len(current_chunk) >= max_words:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "\n",
    "    # Add the last chunk if it's not empty\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Example usage\n",
    "text_chunks = split_text_into_chunks(cleaned_text, max_words=400)\n",
    "print(f\"Total chunks: {len(text_chunks)}\")\n",
    "print(text_chunks[0])  # Print the first chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571193f4-cd63-4607-98ef-66e92fc8a4f0",
   "metadata": {},
   "source": [
    "# üìå 3Ô∏è‚É£ Ensure Chunks Don't Cut Off Mid-Sentence\n",
    "* Instead of splitting blindly every 400 words, we can split by sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70975ac8-b548-4482-ad49-0cef321bc620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total smart chunks: 9\n",
      "arXiv:2503.09776v1 [cs.NI] 12 Mar 2025 A Short Scalability Study on the SeQUeNCe Parallel Quantum Network Simulator Aaron Welch Computational Sciences & Engineering Division Oak Ridge National Laboratory, USA welchda@ornl.gov Mariam Kiran Computational Sciences & Engineering Division Oak Ridge National Laboratory, USA kiranm@ornl.gov Abstract‚ÄîAs quantum networking continues to grow in im- portance, its study is of interest to an ever wider community and at an increasing scale. However, the development of its physical infrastructure remains burdensome, and services providing third- party access are not enough to meet demand. A variety of simulation frameworks provide a method for testing aspects of such systems on commodity hardware, but are predominantly serial and thus unable to scale to larger networks and/or workloads. One effort to address this was focused on parallelising the SeQUeNCe discrete event simulator, though it has yet to be proven to work well across system architectures or at larger scales. Therein lies the contribution of this work ‚Äî to more deeply examine its scalability using ORNL‚Äôs Frontier. Our results provide new insight into its scalability behaviour, and we examine its strategy and how it may be able to be improved. Index Terms‚Äîquantum networking, discrete event simulation, distributed computing I. INTRODUCTION Quantum networks are argued to be the next generation for communication networks that will deliver entanglement and connect distributed quantum physics devices such as quantum computers, sensors, and detectors ‚Äì. Instead of classical ‚Äúbits‚Äù, qubits are transmitted that encode information using the photon spin representation. Quantum networks are being designed to develop ultra-secure and highly accurate sensor networks for science and commercial applications . There are numerous industry efforts developing new hard- ware, protocols, and tools to enable quantum information exchange , using discrete and continuous variable demon- strations, each bringing their own capabilities , Ô¨Åber-optical transmission or free space point-to-point communication. However, network loss plays a huge role in guaranteeing the validity of the quantum states, with current implementations limited to a 300 km distance . Using quantum repeaters, one can extend these to longer distances such that quantum states can be refreshed or preserved ‚Äì. In order to design more efÔ¨Åcient quantum networks and provide a cheap alternative for testing and analysis, quantum network simulations have been developed to help deÔ¨Åne use cases, and collect data to build reliable devices. However, these have been largely sequential and thus limited to small networks and time scales. SeQUeNCe  addresses this limitation by enabling parallel discrete event simulation  that can scale across many processes or nodes .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Adeeshunnikrishnan\\AppData\\Roaming\\nltk_data.\n",
      "[nltk_data]     ..\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def split_text_smart(text, max_words=400):\n",
    "    sentences = sent_tokenize(text)  # Split into sentences\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        current_chunk.append(sentence)\n",
    "        if sum(len(s.split()) for s in current_chunk) >= max_words:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "\n",
    "    # Add last chunk if not empty\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Example usage\n",
    "text_chunks = split_text_smart(cleaned_text, max_words=400)\n",
    "print(f\"Total smart chunks: {len(text_chunks)}\")\n",
    "print(text_chunks[0])  # Print first chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39c62a7-9aaa-42ae-8407-34b615df3aa7",
   "metadata": {},
   "source": [
    "# üîπ  Summarize Each Chunk Using a Hugging Face Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d2cfb0-25f5-407e-ba86-cac4e712cee3",
   "metadata": {},
   "source": [
    "## üìå 1Ô∏è‚É£ Choose a Summarization Model  \n",
    "Hugging Face provides several summarization models:  \n",
    "\n",
    "| Model | Max Token Limit | Best For |\n",
    "|------------|-----------------|-------------|\n",
    "| `facebook/bart-large-cnn` | **1024 tokens (~750 words)** | **General summarization (news, research, etc.)** |\n",
    "| `t5-small`, `t5-base`, `t5-large` | **512 tokens (~400 words)** | **Flexible text summarization** |\n",
    "| `google/pegasus-xsum` | **512 tokens (~400 words)** | **Extremely short summaries** |\n",
    "\n",
    "**Best Choice for Our Task:**  \n",
    "- **BART (`facebook/bart-large-cnn`)** because it can handle **longer text** and produces high-quality summaries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb19f3-44a8-40b5-b7de-4b9dada7caa7",
   "metadata": {},
   "source": [
    "* ‚úÖ Why BART?\n",
    "\n",
    "* Handles long text (up to 1024 tokens).\n",
    "* Produces coherent and informative summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "647bab8f-ae94-4954-a6a9-1fdd00caa2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\adeeshunnikrishnan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Adeeshunnikrishnan\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0c104c-ea05-4706-9707-e8a99bb66f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adeeshunnikrishnan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Adeeshunnikrishnan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) has revolutionized many fields, including machine translation. With the advent of deep learning, NLP models have become more sophisticated, enabling better understanding of human language.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the summarization model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Example test\n",
    "test_text = \"Natural language processing (NLP) has revolutionized many fields, including machine translation, text summarization, and conversational AI. With the advent of deep learning, NLP models have become more sophisticated, enabling better understanding of human language.\"\n",
    "summary = summarizer(test_text, max_length=50, min_length=10, do_sample=False)\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589ce51-0bbd-495d-97cd-51a3411644e7",
   "metadata": {},
   "source": [
    "# üìå 3Ô∏è‚É£ Summarize Each Chunk\n",
    "* Now, we summarize each chunk from our previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9644fa1d-a5ed-4551-be13-500ffcb5cda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum networks are being designed to develop ultra-secure and highly accurate sensor networks for science and commercial applications. Current implementations are limited to a 300 km distance. SeQUeNCe addresses this limitation by enabling parallel discrete event simulation that can scale across many processes or nodes.\n"
     ]
    }
   ],
   "source": [
    "summarized_chunks = []\n",
    "for chunk in text_chunks:\n",
    "    summary = summarizer(chunk, max_length=100, min_length=20, do_sample=False)[0]['summary_text']\n",
    "    summarized_chunks.append(summary)\n",
    "\n",
    "# Print first summarized chunk\n",
    "print(summarized_chunks[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fb489c-5d80-4fa3-af04-864faf31e444",
   "metadata": {},
   "source": [
    "# üìå 4Ô∏è‚É£ Save Summarized Data to CSV\n",
    "* Once we have the summaries, let‚Äôs save them for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddc777be-1d47-4331-820f-5ed1688ab553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization complete! Results saved to 'summarized_research_papers.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "summary_df = pd.DataFrame({\"original_text\": text_chunks, \"summary\": summarized_chunks})\n",
    "summary_df.to_csv(\"summarized_research_papers.csv\", index=False)\n",
    "\n",
    "print(\"Summarization complete! Results saved to 'summarized_research_papers.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98951c-b055-426e-80c7-e07687b561bd",
   "metadata": {},
   "source": [
    "# üìå 1Ô∏è‚É£ Choose an NER Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b1c462-3e74-4c25-9aa3-a158eb52e1f5",
   "metadata": {},
   "source": [
    "* ‚úÖ Best Model for Our Task:\n",
    "* We will use allenai/scibert_scivocab_uncased, since it's trained on scientific papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "076f6aa9-9f7f-4153-9f70-0814e6a244f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adeeshunnikrishnan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Adeeshunnikrishnan\\.cache\\huggingface\\hub\\models--dslim--bert-base-NER. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "C:\\Users\\Adeeshunnikrishnan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\pipelines\\token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.99362546, 'word': 'John Doe', 'start': 31, 'end': 39}, {'entity_group': 'ORG', 'score': 0.99840766, 'word': 'MIT', 'start': 43, 'end': 46}, {'entity_group': 'ORG', 'score': 0.9990243, 'word': 'Google Research', 'start': 69, 'end': 84}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load NER model\n",
    "ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\", grouped_entities=True)\n",
    "\n",
    "# Example text\n",
    "test_text = \"This research was conducted by John Doe at MIT in collaboration with Google Research.\"\n",
    "entities = ner_pipeline(test_text)\n",
    "\n",
    "# Print extracted entities\n",
    "print(entities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e7dec-1f04-4612-9a92-14fef478878d",
   "metadata": {},
   "source": [
    "# üìå 3Ô∏è‚É£ Extract Named Entities from Summarized Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a1c917-0f84-4af3-a4f9-9479606fc646",
   "metadata": {},
   "source": [
    "* Now, let‚Äôs extract key details from our summarized research paper chunks.\n",
    "* ‚úÖ Explanation:\n",
    "\n",
    "* Loops through each summarized chunk and applies NER.\n",
    "* Stores the extracted named entities in extracted_entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da67bb3c-e071-4f3f-8d72-d7b0452e10ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'ORG', 'score': 0.9056627, 'word': 'SeQUeNC', 'start': 195, 'end': 202}]\n"
     ]
    }
   ],
   "source": [
    "extracted_entities = []\n",
    "for summary in summarized_chunks:\n",
    "    entities = ner_pipeline(summary)\n",
    "    extracted_entities.append(entities)\n",
    "\n",
    "# Print entities from the first summarized chunk\n",
    "print(extracted_entities[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6069578-da21-4e2b-bbf8-dbf4b6dda4be",
   "metadata": {},
   "source": [
    "# üìå 4Ô∏è‚É£ Save Extracted Entities to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7bce83f-a855-479d-8ea8-b931f6f36b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity extraction complete! Results saved to 'extracted_entities.csv'.\n"
     ]
    }
   ],
   "source": [
    "entity_list = []\n",
    "\n",
    "for idx, entities in enumerate(extracted_entities):\n",
    "    for entity in entities:\n",
    "        entity_list.append({\n",
    "            \"summary_chunk\": summarized_chunks[idx],\n",
    "            \"entity\": entity['word'],\n",
    "            \"entity_type\": entity['entity_group']\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "entity_df = pd.DataFrame(entity_list)\n",
    "\n",
    "# Save to CSV\n",
    "entity_df.to_csv(\"extracted_entities.csv\", index=False)\n",
    "\n",
    "print(\"Entity extraction complete! Results saved to 'extracted_entities.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27449438-a938-4c42-bf40-29a77862cbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
